import 'package:test/test.dart';
import 'package:blade_parser/blade_parser.dart';

/// Comprehensive edge case tests for Unicode handling in the lexer
/// Tests emoji, RTL text, combining characters, surrogate pairs, and mixed scripts
void main() {
  group('Unicode - Emoji Tests', () {
    late BladeLexer lexer;

    test('Emoji in directive conditions', () {
      lexer = BladeLexer("@if(\$emoji == 'ğŸ˜€')");
      final tokens = lexer.tokenize();

      expect(tokens.any((t) => t.type == TokenType.directiveIf), isTrue);

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value, contains('ğŸ˜€'));
    });

    test('Emoji in echo statements', () {
      lexer = BladeLexer("{{ 'ğŸ‰ Success!' }}");
      final tokens = lexer.tokenize();

      expect(tokens.any((t) => t.type == TokenType.echoOpen), isTrue);

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value, contains('ğŸ‰'));
    });

    test('Multiple emoji in text', () {
      lexer = BladeLexer('<p>ğŸ˜€ğŸ˜ğŸ˜‚ğŸ¤£ğŸ˜ƒ</p>');
      final tokens = lexer.tokenize();

      final textTokens = tokens.where((t) => t.type == TokenType.text).toList();
      final combinedText = textTokens.map((t) => t.value).join();
      expect(combinedText, contains('ğŸ˜€'));
      expect(combinedText, contains('ğŸ˜‚'));
      expect(combinedText, contains('ğŸ˜ƒ'));
    });

    test('Emoji with skin tone modifiers', () {
      lexer = BladeLexer("{{ 'ğŸ‘‹ğŸ½' }}");
      final tokens = lexer.tokenize();

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value, contains('ğŸ‘‹ğŸ½'));
    });
  });

  group('Unicode - RTL Text Tests', () {
    late BladeLexer lexer;

    test('Arabic text in directives', () {
      lexer = BladeLexer("@if(\$lang == 'Ù…Ø±Ø­Ø¨Ø§')");
      final tokens = lexer.tokenize();

      expect(tokens.any((t) => t.type == TokenType.directiveIf), isTrue);

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value, contains('Ù…Ø±Ø­Ø¨Ø§'));
    });

    test('Hebrew text in echo', () {
      lexer = BladeLexer("{{ '×©×œ×•×' }}");
      final tokens = lexer.tokenize();

      expect(tokens.any((t) => t.type == TokenType.echoOpen), isTrue);

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value, contains('×©×œ×•×'));
    });

    test('Mixed LTR and RTL text', () {
      lexer = BladeLexer('<p>Hello Ù…Ø±Ø­Ø¨Ø§ ×©×œ×•× World</p>');
      final tokens = lexer.tokenize();

      final textTokens = tokens.where((t) => t.type == TokenType.text).toList();
      final combinedText = textTokens.map((t) => t.value).join();
      expect(combinedText, contains('Hello'));
      expect(combinedText, contains('Ù…Ø±Ø­Ø¨Ø§'));
      expect(combinedText, contains('×©×œ×•×'));
      expect(combinedText, contains('World'));
    });
  });

  group('Unicode - Zero-Width Characters', () {
    late BladeLexer lexer;

    test('Zero-Width Joiner (ZWJ) in text', () {
      // ZWJ is U+200D, used to combine emoji
      const zwj = '\u200D';
      lexer = BladeLexer("{{ 'ğŸ‘¨$zwjğŸ‘©$zwjğŸ‘§' }}");
      final tokens = lexer.tokenize();

      expect(tokens.any((t) => t.type == TokenType.echoOpen), isTrue);

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value, contains(zwj));
    });

    test('Zero-Width Non-Joiner (ZWNJ) in text', () {
      // ZWNJ is U+200C, used in some languages like Persian
      const zwnj = '\u200C';
      lexer = BladeLexer("{{ 'Ù…ÛŒ$zwnjØ®ÙˆØ§Ù‡Ù…' }}");
      final tokens = lexer.tokenize();

      expect(tokens.any((t) => t.type == TokenType.echoOpen), isTrue);

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value, contains(zwnj));
    });

    test('Zero-Width Space (U+200B) in attributes', () {
      const zws = '\u200B';
      lexer = BladeLexer('<div data-value="test${zws}value">Content</div>');
      final tokens = lexer.tokenize();

      final attributeValueTokens =
          tokens.where((t) => t.type == TokenType.attributeValue).toList();
      expect(attributeValueTokens, isNotEmpty);
      expect(attributeValueTokens.any((t) => t.value.contains(zws)), isTrue);
    });
  });

  group('Unicode - Combining Diacritics', () {
    late BladeLexer lexer;

    test('Combining diacritics in variable names', () {
      // Note: Most languages don't allow combining marks in identifiers,
      // but we should handle them in strings
      lexer = BladeLexer("{{ 'cafÃ©' }}");
      final tokens = lexer.tokenize();

      expect(tokens.any((t) => t.type == TokenType.echoOpen), isTrue);

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value, contains('cafÃ©'));
    });

    test('Vietnamese with multiple diacritics', () {
      lexer = BladeLexer("{{ 'Tiáº¿ng Viá»‡t' }}");
      final tokens = lexer.tokenize();

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value, contains('Tiáº¿ng'));
      expect(expressionTokens.first.value, contains('Viá»‡t'));
    });
  });

  group('Unicode - Surrogate Pairs', () {
    late BladeLexer lexer;

    test('Emoji as surrogate pairs', () {
      // Emoji beyond BMP are represented as surrogate pairs
      lexer = BladeLexer("{{ 'ğ•³ğ–Šğ–‘ğ–‘ğ–”' }}");
      final tokens = lexer.tokenize();

      expect(tokens.any((t) => t.type == TokenType.echoOpen), isTrue);

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value.isNotEmpty, isTrue);
    });

    test('Mathematical Alphanumeric Symbols', () {
      // These are in the Supplementary Multilingual Plane
      lexer = BladeLexer("{{ 'ğ’œğ’·ğ’¸' }}");
      final tokens = lexer.tokenize();

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value.isNotEmpty, isTrue);
    });
  });

  group('Unicode - BOM and Special Markers', () {
    late BladeLexer lexer;

    test('BOM (Byte Order Mark) at start', () {
      // BOM is U+FEFF
      const bom = '\uFEFF';
      lexer = BladeLexer('$bom@if(\$x)');
      final tokens = lexer.tokenize();

      // BOM should be treated as whitespace or text, directive should still be recognized
      expect(tokens.any((t) => t.type == TokenType.directiveIf), isTrue);
    });

    test('BOM in middle of content', () {
      const bom = '\uFEFF';
      lexer = BladeLexer('<p>Hello${bom}World</p>');
      final tokens = lexer.tokenize();

      final textTokens = tokens.where((t) => t.type == TokenType.text).toList();
      expect(textTokens, isNotEmpty);
    });
  });

  group('Unicode - Mixed Scripts', () {
    late BladeLexer lexer;

    test('Latin + Cyrillic + CJK mixed', () {
      lexer = BladeLexer("{{ 'Hello ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ ä½ å¥½ ã“ã‚“ã«ã¡ã¯' }}");
      final tokens = lexer.tokenize();

      expect(tokens.any((t) => t.type == TokenType.echoOpen), isTrue);

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value, contains('Hello'));
      expect(expressionTokens.first.value, contains('ĞŸÑ€Ğ¸Ğ²ĞµÑ‚'));
      expect(expressionTokens.first.value, contains('ä½ å¥½'));
      expect(expressionTokens.first.value, contains('ã“ã‚“ã«ã¡ã¯'));
    });

    test('Mixed scripts in HTML content', () {
      lexer = BladeLexer('<p>English EspaÃ±ol ä¸­æ–‡ æ—¥æœ¬èª í•œêµ­ì–´ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ×¢×‘×¨×™×ª</p>');
      final tokens = lexer.tokenize();

      final textTokens = tokens.where((t) => t.type == TokenType.text).toList();
      final combinedText = textTokens.map((t) => t.value).join();
      expect(combinedText, contains('English'));
      expect(combinedText, contains('EspaÃ±ol'));
      expect(combinedText, contains('ä¸­æ–‡'));
      expect(combinedText, contains('æ—¥æœ¬èª'));
      expect(combinedText, contains('í•œêµ­ì–´'));
      expect(combinedText, contains('Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©'));
      expect(combinedText, contains('×¢×‘×¨×™×ª'));
    });

    test('Mixed scripts in directive expressions', () {
      lexer = BladeLexer("@if(\$lang == 'ä¸­æ–‡' || \$lang == 'Ğ ÑƒÑÑĞºĞ¸Ğ¹')");
      final tokens = lexer.tokenize();

      expect(tokens.any((t) => t.type == TokenType.directiveIf), isTrue);

      final expressionTokens =
          tokens.where((t) => t.type == TokenType.expression).toList();
      expect(expressionTokens.length, equals(1));
      expect(expressionTokens.first.value, contains('ä¸­æ–‡'));
      expect(expressionTokens.first.value, contains('Ğ ÑƒÑÑĞºĞ¸Ğ¹'));
    });
  });
}
